{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Omniglot:\n",
    "    def __init__(self, bsize=32, N=5, K=5, Q=15):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            bsize = batch size\n",
    "            N = N-way\n",
    "            K = K-shot\n",
    "            Q = Num of query\n",
    "        \"\"\"\n",
    "        assert K+Q <= 20, \"num of K + num of Q should be less than 20\"\n",
    "        self.bsize=bsize\n",
    "        self.N=N\n",
    "        self.K=K\n",
    "        self.Q=Q\n",
    "        \n",
    "        self.dtrain=torchvision.datasets.Omniglot(\n",
    "            root=\"./omniglot\", background=True, download=True, transform = transform.Compose([transform.Resize([28,28], interpolation=2), \n",
    "                                                                                              transform.ToTensor()])\n",
    "        )\n",
    "        self.dtest=torchvision.datasets.Omniglot(\n",
    "            root=\"./omniglot\", background=False, download=True, transform = transform.Compose([transform.Resize([28,28], interpolation=2), \n",
    "                                                                                              transform.ToTensor()])\n",
    "        )\n",
    "        \n",
    "        self.data_num = len(self.dtrain)+len(self.dtest) \n",
    "        self.cls_num = int(self.data_num/20)\n",
    "                           \n",
    "        print('Num of total cls :', self.cls_num)\n",
    "        print('Num of total data :',  self.data_num)\n",
    "        \n",
    "    def get_task(self, mode='train'):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            mode : 'train' or 'test'\n",
    "        \"\"\"\n",
    "        if mode=='train':\n",
    "            dset = self.dtrain\n",
    "            cls_num = int(len(self.dtrain)/20)\n",
    "        else:\n",
    "            dset = self.dtest\n",
    "            cls_num = int(len(self.dtest)/20)\n",
    "            \n",
    "        spt_xs=torch.zeros([self.bsize, self.N*self.K, 28, 28])\n",
    "        spt_ys=torch.zeros([self.bsize, self.N*self.K], dtype=torch.int64)\n",
    "        qry_xs=torch.zeros([self.bsize, self.N*self.Q, 28, 28])\n",
    "        qry_ys=torch.zeros([self.bsize, self.N*self.Q], dtype=torch.int64)\n",
    "        \n",
    "        for i in range(self.bsize):\n",
    "            n_way = np.random.choice(cls_num, self.N, replace=False)\n",
    "            \n",
    "            spt_x=torch.zeros([self.N, self.K,28,28])\n",
    "            spt_y=torch.zeros([self.N, self.K])\n",
    "            qry_x=torch.zeros([self.N, self.Q,28,28])\n",
    "            qry_y=torch.zeros([self.N, self.Q])\n",
    "             \n",
    "            for j, idx in enumerate(n_way):\n",
    "                spt_x_, _ = zip(*[dset[i] for i in range(idx*20, idx*20+self.K)])\n",
    "                spt_x[j] = torch.stack(spt_x_).resize(self.K,28,28)\n",
    "                spt_y[j] = torch.tensor([j for k in range(self.K)])\n",
    "                qry_x_, _ = zip(*[dset[i] for i in range(idx*20+self.K, idx*20+self.K+self.Q)])\n",
    "                perm = torch.randperm(self.N * self.Q)\n",
    "                qry_x[j] = torch.stack(qry_x_).resize(self.Q,28,28)\n",
    "                qry_y[j] = torch.tensor([j for k in range(self.Q)])\n",
    "            \n",
    "            perm = torch.randperm(self.N * self.K)\n",
    "            spt_xs[i] = spt_x.reshape(self.N * self.K, 28, 28)[perm]\n",
    "            spt_ys[i] = spt_y.reshape(self.N * self.K)[perm]\n",
    "            perm = torch.randperm(self.N * self.Q)\n",
    "            qry_xs[i] = qry_x.reshape(self.N * self.Q, 28, 28)[perm]\n",
    "            qry_ys[i] = qry_y.reshape(self.N * self.Q)[perm]\n",
    "        \n",
    "        return spt_xs, spt_ys, qry_xs, qry_ys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner(nn.Module):\n",
    "    def __init__(self, N):\n",
    "        nn.Module.__init__(self)\n",
    "        \"\"\"\n",
    "        params:\n",
    "            N : Num of class to classify\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "        \n",
    "        in_channel = 1\n",
    "        out_channel = 64\n",
    "        \n",
    "        layers = []\n",
    "        #4 layers with BN and ReLU for feature extractor\n",
    "        for i in range(4):\n",
    "            layers += [nn.Conv2d(in_channel, out_channel, 3, 2, 1), nn.BatchNorm2d(out_channel), nn.ReLU()]\n",
    "            in_channel=out_channel\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        #N-way classfier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256, N),\n",
    "            nn.LogSoftmax(1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            x : input image to classify\n",
    "        \"\"\"\n",
    "        out = x.view(-1, 1, 28, 28)\n",
    "        out = self.layers(out)\n",
    "        out = out.view(len(out), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def pred(self, x, y):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            x : input image to predict\n",
    "            y : label for x\n",
    "        \"\"\"\n",
    "        x=self.forward(x)\n",
    "        _, pred = x.max(1)\n",
    "        accs = (pred==y).sum()/float(len(y))\n",
    "        return pred, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaLearner(nn.Module):\n",
    "    def __init__(self, bsize=32, N=5, K=5, Q=15):\n",
    "        \"\"\"\n",
    "        params:\n",
    "            bsize : batchsize\n",
    "            N, K : N-way k-shot\n",
    "            Q : Num of query data(for each class)\n",
    "        \"\"\"\n",
    "        nn.Module.__init__(self)\n",
    "        self.bsize=32\n",
    "        self.N=N\n",
    "        self.K=5\n",
    "        self.Q=Q\n",
    "        self.net = Learner(N)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reptile_train(meta, dset, meta_lr, lr, train_num=5, epoch=1, bsize=32):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        meta : Meta learner module\n",
    "        dset : omniglot dataset\n",
    "        meta lr : learning rate for meta learner\n",
    "        lr : learning rate for learner\n",
    "        train_num : num of train for each task\n",
    "        epoch : epcoh\n",
    "        bsize : batchszie\n",
    "    \"\"\"\n",
    "    CE = nn.CrossEntropyLoss()\n",
    "    \n",
    "    #get the task from dset\n",
    "    mspt_x, mspt_y, mqry_x, mqry_y = dset.get_task('test')\n",
    "    mspt_x = torch.autograd.Variable(mspt_x)\n",
    "    mspt_y = torch.autograd.Variable(mspt_y)\n",
    "    mqry_x = torch.autograd.Variable(mqry_x)\n",
    "    mqry_y = torch.autograd.Variable(mqry_y)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        CE=CE.cuda()\n",
    "        mspt_x=mspt_x.cuda()\n",
    "        mspt_y=mspt_y.cuda()\n",
    "        mqry_x=mqry_x.cuda()\n",
    "        mqry_y=mqry_y.cuda()\n",
    "   \n",
    "    #train for metalearner\n",
    "    for i in range(epoch):\n",
    "        meta_lr = meta_lr*(epoch-i)/epoch\n",
    "        \n",
    "        meta.train()\n",
    "        \n",
    "        spt_x, spt_y, qry_x, qry_y = dset.get_task('train')\n",
    "        spt_x = torch.autograd.Variable(spt_x)\n",
    "        spt_y = torch.autograd.Variable(spt_y)\n",
    "        qry_x = torch.autograd.Variable(qry_x)\n",
    "        qry_y = torch.autograd.Variable(qry_y) \n",
    "       \n",
    "        if torch.cuda.is_available(): \n",
    "            spt_x=spt_x.cuda()\n",
    "            spt_y=spt_y.cuda()\n",
    "            qry_x=qry_x.cuda()\n",
    "            qry_y=qry_y.cuda()\n",
    "        \n",
    "        meta_param = meta.net.state_dict()\n",
    "        gradient = {name : 0 for name in meta_param}\n",
    "        \n",
    "        for j in range(bsize):\n",
    "            learner = copy.deepcopy(meta.net)\n",
    "            optim = torch.optim.SGD(learner.parameters(), lr = lr)\n",
    "            learner.train()\n",
    "            \n",
    "            #train each task for learner\n",
    "            for k in range(train_num):\n",
    "                score = learner(spt_x[j])\n",
    "                loss = CE(score, spt_y[j])\n",
    "                optim.zero_grad()\n",
    "                loss.backward()\n",
    "                optim.step()            \n",
    "            \n",
    "            #Theta = Theta + epsilon * (1/batch size) * sigma(W - Theta), Equation in paper \n",
    "            learner_param = learner.state_dict()\n",
    "            for name in gradient:\n",
    "                gradient[name] = gradient[name] + (learner_param[name] - meta_param[name])\n",
    "                \n",
    "        meta.net.load_state_dict(({name : meta_param[name] + meta_lr * (gradient[name] / bsize) for name in meta_param}))\n",
    "        \n",
    "        \n",
    "        #evaluation\n",
    "        if i%10==0:\n",
    "            pre_acc=0\n",
    "            after_acc=0\n",
    "            temp=0\n",
    "            \n",
    "            losses=0\n",
    "            \n",
    "            for j in range(bsize):\n",
    "                learner = copy.deepcopy(meta.net)\n",
    "                optim = torch.optim.SGD(learner.parameters(), lr = lr)\n",
    "                \n",
    "                #accuracy before learning\n",
    "                _, acc= learner.pred(mqry_x[j], mqry_y[j])\n",
    "                pre_acc=pre_acc+acc\n",
    "                \n",
    "                #train the learner model\n",
    "                learner.train()\n",
    "                \n",
    "                for k in range(train_num):\n",
    "                    score = learner(mspt_x[j])\n",
    "                    loss = CE(score, mspt_y[j])\n",
    "                    losses=losses+loss\n",
    "\n",
    "                    optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "                    \n",
    "                learner.eval()\n",
    "                \n",
    "                #accuracy after t\n",
    "                _, acc= learner.pred(mqry_x[j], mqry_y[j])\n",
    "                after_acc = after_acc+acc\n",
    "                \n",
    "            print(\"Epoch \",i, \":\")\n",
    "            print(\"loss :\", losses/bsize)\n",
    "            print(\"accuracy before training : \", pre_acc/bsize)\n",
    "            print(\"accuracy after training : \", after_acc/bsize)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsize=32\n",
    "N=5\n",
    "K=5\n",
    "Q=5\n",
    "epoch=1000\n",
    "\n",
    "omniglot = Omniglot(bsize=bsize, N=N, K=K, Q=Q)\n",
    "meta = MetaLearner(bsize=bsize, N=N,K=K,Q=Q)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"cuda is on\")\n",
    "    meta.cuda()\n",
    "    \n",
    "reptile_train(meta=meta, dset=omniglot, meta_lr= 0.5, lr=0.01, train_num=5, epoch=epoch, bsize=bsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
